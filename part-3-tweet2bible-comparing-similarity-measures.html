<!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>  3. Tweet2Bible - Comparing Similarity Measures | Practical Machine Learning Adventures
</title>
  <link rel="canonical" href="https://benhoyle.github.io/part-3-tweet2bible-comparing-similarity-measures.html">


  <link rel="stylesheet" href="https://benhoyle.github.io/theme/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.9/css/all.css" integrity="sha384-5SOiIsAziJl6AWe0HWRKTXlfcSHKmYV4RBF18PPJ173Kzn7jzMyFuTtk8JA7QQG1" crossorigin="anonymous">
  <link rel="stylesheet" href="https://benhoyle.github.io/theme/css/pygments/default.min.css">
  <link rel="stylesheet" href="https://benhoyle.github.io/theme/css/theme.css">

  <link rel="alternate" type="application/atom+xml" title="Full Atom Feed"
        href="https://benhoyle.github.io/feeds/all.atom.xml">
  <link rel="alternate" type="application/atom+xml" title="Categories Atom Feed"
        href="https://benhoyle.github.io/feeds/tweet2bible.atom.xml">  
  <meta name="description" content="This post looks at some approaches for matching tweets to Bible passages.">
  <script>
    (function(i, s, o, g, r, a, m) {
      i['GoogleAnalyticsObject'] = r;
      i[r] = i[r] || function() {
        (i[r].q = i[r].q || []).push(arguments)
      }, i[r].l = 1 * new Date();
      a = s.createElement(o);
      a.async = 1;
      a.src = g;
      m = s.getElementsByTagName(o)[0];
      m.parentNode.insertBefore(a, m)
    })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
    ga('create', 'UA-96290248-2', 'auto');
    ga('send', 'pageview');
  </script>


</head>

<body>
  <header class="header">
    <div class="container">
<div class="row">
  <div class="col-sm-12">
    <h1 class="title"><a href="https://benhoyle.github.io/">Practical Machine Learning Adventures</a></h1>
      <p class="text-muted">A selection of machine learning projects</p>
  </div>
</div>    </div>
  </header>

  <div class="main">
    <div class="container">
  <article class="article">
    <div class="content">
      <h1>3. Tweet2Bible - Comparing Similarity Measures</h1>
<p>Now we have our data we can look at some matching.</p>
<p>To start we will look at a number of off-the-shelf similarity functions. We will then compare these subjectively and see what gets us the best matches.</p>
<h2>Similarity Functions</h2>
<p>Here are some initial similarity functions we can look at:</p>
<ul>
<li><a href="https://docs.python.org/3/library/difflib.html">Difflib's SequenceMatcher</a> has a "ratio" function that provides a match score for two strings. This represents a "naive" baseline.</li>
<li>We can use spaCy's <a href="https://spacy.io/usage/vectors-similarity">"similarity" method</a> on "doc" objects (i.e. as applied to each string).</li>
<li>We can apply the techniques set available in Gensim as set out in <a href="https://radimrehurek.com/gensim/tut3.html">this helpful tutorial</a>.</li>
</ul>
<p>We can then use the results as a baseline for more complex models and algorithms.</p>
<p>We will also time how long each method takes.</p>
<h3>Load Data</h3>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">logging</span>
<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">format</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%(asctime)s</span><span class="s1"> : </span><span class="si">%(levelname)s</span><span class="s1"> : </span><span class="si">%(message)s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pickle</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;processed_data.pkl&quot;</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">tweets</span><span class="p">,</span> <span class="n">bible_data</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">&quot;We have {0} tweets.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tweets</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;We have {0} Bible passages.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">bible_data</span><span class="p">)))</span>
</pre></div>


<div class="highlight"><pre><span></span>We have 9806 tweets.
We have 31102 Bible passages.
</pre></div>


<hr>
<h3>Difflib SequenceMatcher</h3>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">difflib</span> <span class="kn">import</span> <span class="n">SequenceMatcher</span>

<span class="k">def</span> <span class="nf">similar</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get a similarity metric for strings a and b&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">SequenceMatcher</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span><span class="o">.</span><span class="n">ratio</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">get_matches</span><span class="p">(</span><span class="n">tweet</span><span class="p">,</span> <span class="n">bible_data</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Match a tweet against the bible_data.&quot;&quot;&quot;</span>
    <span class="c1"># Get matches</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="n">verse</span><span class="p">,</span> <span class="n">passage</span><span class="p">,</span> <span class="n">similar</span><span class="p">(</span><span class="n">tweet</span><span class="p">,</span> <span class="n">passage</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">verse</span><span class="p">,</span> <span class="n">passage</span> <span class="ow">in</span> <span class="n">bible_data</span>
    <span class="p">]</span>
    <span class="c1"># Sort by descending score</span>
    <span class="n">scores</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">tup</span><span class="p">:</span> <span class="n">tup</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">reverse</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">scores</span>

<span class="k">def</span> <span class="nf">test_random_tweets</span><span class="p">(</span><span class="n">tweets</span><span class="p">,</span> <span class="n">bible_data</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Print n examples for k tweets selected at random.&quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">random</span>
    <span class="n">num_tweets</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tweets</span><span class="p">)</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_tweets</span><span class="p">),</span> <span class="n">k</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>
        <span class="n">tweet</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;-----------------&quot;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Tweet text: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tweet</span><span class="p">))</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">get_matches</span><span class="p">(</span><span class="n">tweet</span><span class="p">,</span> <span class="n">bible_data</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">verse</span><span class="p">,</span> <span class="n">passage</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">n</span><span class="p">]:</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">{0}, {1}, {2}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">verse</span><span class="p">,</span> <span class="n">passage</span><span class="p">,</span> <span class="n">score</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">test_random_tweets</span><span class="p">(</span><span class="n">tweets</span><span class="p">,</span> <span class="n">bible_data</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>-----------------
Tweet text: &quot;In addition, along with the advance of the electronic information society, a variety of electronic devices are utilized.&quot; #thetimeswelivein

Mark 8:19, When I broke the five loaves among the five thousand, how many baskets full of broken pieces did you take up? They told him, Twelve., 0.4338235294117647

Exodus 6:16, These are the names of the sons of Levi according to their generations: Gershon, and Kohath, and Merari; and the years of the life of Levi were one hundred thirty-seven years., 0.43174603174603177

Numbers 3:21, Of Gershon was the family of the Libnites, and the family of the Shimeites: these are the families of the Gershonites., 0.4186046511627907

Job 4:10, The roaring of the lion, and the voice of the fierce lion, the teeth of the young lions, are broken., 0.4166666666666667

2 Corinthians 3:9, For if the service of condemnation has glory, the service of righteousness exceeds much more in glory., 0.4132231404958678
-----------------
Tweet text: RT @Dr_Cuspy: Why Watson and Siri Are Not Real AI http://t.co/s5MsxRK7Nd via @PopMech [Hofstadter pops up again; a renaissance?]

Exodus 2:22, She bore a son, and he named him Gershom, for he said, I have lived as a foreigner in a foreign land., 0.35807860262008734

2 Kings 3:22, They rose up early in the morning, and the sun shone on the water, and the Moabites saw the water over against them as red as blood., 0.35384615384615387

Job 30:20, I cry to you, and you do not answer me. I stand up, and you gaze at me., 0.35175879396984927

Job 38:26, To cause it to rain on a land where no man is; on the wilderness, in which there is no man;, 0.3470319634703196

Genesis 34:31, They said, Should he deal with our sister as with a prostitute?, 0.34554973821989526
-----------------
Tweet text: EPO - The Administrative Council has been busy: updates concerning international supplementary searches, fees &amp; search sharing coming up...

Judges 1:21, The children of Benjamin did not drive out the Jebusites who inhabited Jerusalem; but the Jebusites dwell with the children of Benjamin in Jerusalem to this day., 0.3933333333333333

2 Timothy 2:18, men who have erred concerning the truth, saying that the resurrection is already past, and overthrowing the faith of some., 0.39080459770114945

Acts 15:9, He made no distinction between us and them, cleansing their hearts by faith., 0.39069767441860465

Hebrews 11:38, (of whom the world was not worthy), wandering in deserts, mountains, caves, and the holes of the earth., 0.3884297520661157

Joshua 13:28, This is the inheritance of the children of Gad according to their families, the cities and its villages., 0.3868312757201646
-----------------
Tweet text: Historians (and journalists) are always going to be important. https://t.co/o4s7DJEYwE

Leviticus 9:16, He presented the burnt offering, and offered it according to the ordinance., 0.40993788819875776

Job 36:33, Its noise tells about him, and the livestock also concerning the storm that comes up., 0.4093567251461988

Proverbs 16:11, Honest balances and scales are Yahweh&#39;s; all the weights in the bag are his work., 0.40718562874251496

John 20:10, So the disciples went away again to their own homes., 0.4057971014492754

Acts 3:1, Peter and John were going up into the temple at the hour of prayer, the ninth hour., 0.40236686390532544
-----------------
Tweet text: Tip: use Chromium on Karmic EeePC in full screen (F11): excellent use of limited space.

Isaiah 28:29, This also comes forth from Yahweh of Armies, who is wonderful in counsel, and excellent in wisdom., 0.44324324324324327

Psalm 139:15, My frame wasn&#39;t hidden from you, when I was made in secret, woven together in the depths of the earth., 0.4126984126984127

Hebrews 1:4, having become so much better than the angels, as he has inherited a more excellent name than they have., 0.4105263157894737

Job 12:21, He pours contempt on princes, and loosens the belt of the strong., 0.40789473684210525

Deuteronomy 25:10, His name shall be called in Israel, The house of him who has his shoe untied., 0.4024390243902439
</pre></div>


<hr>
<h3>spaCy String Similarity</h3>
<p>The 'en_core_web_lg' file crashed my Jupyter kernel but the 'en_core_web_sm' file loaded okay. I'll try the medium-sized file 'en_core_web_md'. Yes - 'md' file loaded okay.</p>
<p>Spacy uses an <a href="https://spacy.io/usage/vectors-similarity#custom-similarity">average of the word vectors in a span or doc</a>. (It may be faster to join the passages as a doc - process then split into spans.)</p>
<div class="highlight"><pre><span></span><span class="err">!</span><span class="n">python3</span> <span class="o">-</span><span class="n">m</span> <span class="n">spacy</span> <span class="n">download</span> <span class="n">en_core_web_md</span>
</pre></div>


<div class="highlight"><pre><span></span>    You can now load the model via spacy.load(&#39;en_core_web_md&#39;)
</pre></div>


<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">spacy</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;en_core_web_md&#39;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">similar</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get a similarity metric for strings a and b&quot;&quot;&quot;</span>
    <span class="n">spacy_a</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">spacy_b</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">spacy_a</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="n">spacy_b</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">test_random_tweets</span><span class="p">(</span><span class="n">tweets</span><span class="p">,</span> <span class="n">bible_data</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>-----------------
Tweet text: Next-Gen Bluetooth Bulb Controllable Via Smartphone | Freshome http://t.co/5oEjvL6c [A great patented idea - get it to market!]

Nehemiah 3:32, Between the ascent of the corner and the sheep gate repaired the goldsmiths and the merchants., 0.38009049773755654

Jeremiah 27:5, I have made the earth, the men and the animals that are on the surface of the earth, by my great power and by my outstretched arm; and I give it to whom it seems right to me., 0.3588039867109635

1 Corinthians 10:7, Neither be idolaters, as some of them were. As it is written, The people sat down to eat and drink, and rose up to play., 0.3562753036437247

Acts 2:20, The sun will be turned into darkness, and the moon into blood, before the great and glorious day of the Lord comes., 0.35537190082644626

Matthew 18:4, Whoever therefore humbles himself as this little child, the same is the greatest in the Kingdom of Heaven., 0.351931330472103
-----------------
Tweet text: Ask Yourself: Are You Happier Now Than You Were 10 Years Ago? https://t.co/1MeEzAkHcT [+ report on happiness &amp;amp; parenting: -ve ~ w/ GDP]

Hosea 8:8, Israel is swallowed up. Now they are among the nations like a worthless thing., 0.35023041474654376

Deuteronomy 29:4, but Yahweh has not given you a heart to know, and eyes to see, and ears to hear, to this day., 0.33620689655172414

Amos 6:12, Do horses run on the rocky crags? Does one plow there with oxen? But you have turned justice into poison, and the fruit of righteousness into bitterness;, 0.3356164383561644

Ephesians 4:28, Let him who stole steal no more; but rather let him labor, working with his hands the thing that is good, that he may have something to give to him who has need., 0.3333333333333333

Psalm 112:1, Praise Yah! Blessed is the man who fears Yahweh, who delights greatly in his commandments., 0.3318777292576419
-----------------
Tweet text: The more possessions a person has, &amp;amp; the more orderly the society, the greater the frequency of corporal punishment for children.

1 Chronicles 26:19, These were the divisions of the doorkeepers; of the sons of the Korahites, and of the sons of Merari., 0.4700854700854701

1 Samuel 17:31, When the words were heard which David spoke, they rehearsed them before Saul; and he sent for him., 0.4588744588744589

2 Kings 20:4, It happened, before Isaiah had gone out into the middle part of the city, that the word of Yahweh came to him, saying,, 0.4541832669322709

Exodus 39:38, the golden altar, the anointing oil, the sweet incense, the screen for the door of the Tent,, 0.4533333333333333

Ezekiel 47:15, This shall be the border of the land: On the north side, from the great sea, by the way of Hethlon, to the entrance of Zedad;, 0.4496124031007752
-----------------
Tweet text: Rather than use subordinate clauses, old languages (~ C10 BC) juxtapose events according to temporal order.

Genesis 30:34, Laban said, Behold, let it be according to your word., 0.475

Numbers 15:12, According to the number that you shall prepare, so you shall do to everyone according to their number., 0.45933014354066987

Numbers 26:53, To these the land shall be divided for an inheritance according to the number of names., 0.4329896907216495

2 Kings 4:44, So he set it before them, and they ate, and left some of it, according to the word of Yahweh., 0.43

2 Kings 7:16, The people went out, and plundered the camp of the Syrians. So a measure of fine flour was [sold] for a shekel, and two measures of barley for a shekel, according to the word of Yahweh., 0.4246575342465753
-----------------
Tweet text: The Economist | Amazon: http://t.co/wBm32F26yw [the world&#39;s 9th biggest retailer didn&#39;t exist 20 years ago] http://t.co/JY6Uq3iSIB

2 Thessalonians 2:6, Now you know what is restraining him, to the end that he may be revealed in his own season., 0.39819004524886875

Mark 16:13, They went away and told it to the rest. They didn&#39;t believe them, either., 0.39408866995073893

John 14:24, He who doesn&#39;t love me doesn&#39;t keep my words. The word which you hear isn&#39;t mine, but the Father&#39;s who sent me., 0.37344398340248963

1 Timothy 6:7, For we brought nothing into the world, and we certainly can&#39;t carry anything out., 0.3696682464454976

Proverbs 13:1, A wise son listens to his father&#39;s instruction, but a scoffer doesn&#39;t listen to rebuke., 0.3686635944700461
</pre></div>


<hr>
<h3>Gensim</h3>
<p>Gensim needs a little bit of pre-processing to convert our texts into vector form. We need to get a bag of words that represents each portion of text.</p>
<p>First we need to tokenise our text. We can use spaCy or NLTK to do this. (The method above involves generating a spaCy doc for each Bible passage - we can maybe do this once and then use elsewhere.)</p>
<p>Then we filter the text and convert it into a vector form.</p>
<p>The procedure below mirrors the <a href="https://radimrehurek.com/gensim/tut1.html">Gensim tutorial</a>.</p>
<div class="highlight"><pre><span></span><span class="c1"># This took quite a long time so I might go for the quicker word_tokenize from nltk</span>
<span class="c1"># spacy_bible = [(verse, nlp(passage)) for verse, passage in bible_data]</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nltk</span> <span class="kn">import</span> <span class="n">word_tokenize</span>
<span class="n">tokenised</span> <span class="o">=</span> <span class="p">[(</span><span class="n">verse</span><span class="p">,</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">passage</span><span class="p">))</span> <span class="k">for</span> <span class="n">verse</span><span class="p">,</span> <span class="n">passage</span> <span class="ow">in</span> <span class="n">bible_data</span><span class="p">]</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">tokenised</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
</pre></div>


<div class="highlight"><pre><span></span>(&#39;Genesis 1:4&#39;,
 [&#39;God&#39;,
  &#39;saw&#39;,
  &#39;the&#39;,
  &#39;light&#39;,
  &#39;,&#39;,
  &#39;and&#39;,
  &#39;saw&#39;,
  &#39;that&#39;,
  &#39;it&#39;,
  &#39;was&#39;,
  &#39;good&#39;,
  &#39;.&#39;,
  &#39;God&#39;,
  &#39;divided&#39;,
  &#39;the&#39;,
  &#39;light&#39;,
  &#39;from&#39;,
  &#39;the&#39;,
  &#39;darkness&#39;,
  &#39;.&#39;])
</pre></div>


<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">process_words</span><span class="p">(</span><span class="n">tokens</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Remove digits and punctuation from text and convert to lower case. &quot;&quot;&quot;</span>
    <span class="c1"># Alternative for complete text is re.sub(&#39;\W+&#39;, &#39;&#39;, text)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="n">w</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()]</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">tokenised</span> <span class="o">=</span> <span class="p">[(</span><span class="n">verse</span><span class="p">,</span> <span class="n">process_words</span><span class="p">(</span><span class="n">tokens</span><span class="p">))</span> <span class="k">for</span> <span class="n">verse</span><span class="p">,</span> <span class="n">tokens</span> <span class="ow">in</span> <span class="n">tokenised</span><span class="p">]</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">tokenised</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
</pre></div>


<div class="highlight"><pre><span></span>(&#39;Genesis 1:4&#39;,
 [&#39;god&#39;,
  &#39;saw&#39;,
  &#39;the&#39;,
  &#39;light&#39;,
  &#39;and&#39;,
  &#39;saw&#39;,
  &#39;that&#39;,
  &#39;it&#39;,
  &#39;was&#39;,
  &#39;good&#39;,
  &#39;god&#39;,
  &#39;divided&#39;,
  &#39;the&#39;,
  &#39;light&#39;,
  &#39;from&#39;,
  &#39;the&#39;,
  &#39;darkness&#39;])
</pre></div>


<div class="highlight"><pre><span></span><span class="n">texts</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokens</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">tokens</span> <span class="ow">in</span> <span class="n">tokenised</span><span class="p">]</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># Import NLTK modules</span>
<span class="kn">from</span> <span class="nn">nltk</span> <span class="kn">import</span> <span class="n">word_tokenize</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="c1"># Load stopwords</span>
<span class="n">ENG_STOPWORDS</span> <span class="o">=</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">text_preprocessing</span><span class="p">(</span><span class="n">original_text</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Clean and process texts for Gensim methods.&quot;&quot;&quot;</span>
    <span class="c1"># Tokenise</span>
    <span class="n">tokenised</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">original_text</span><span class="p">)</span>

    <span class="c1"># Convert to lowercase and remove non-text / stopwords</span>
    <span class="n">tokenised</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">tokenised</span> <span class="k">if</span> <span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()</span> <span class="ow">and</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ENG_STOPWORDS</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">tokenised</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">text_preprocessing</span><span class="p">(</span><span class="n">bible_data</span><span class="p">[</span><span class="mi">3</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
</pre></div>


<div class="highlight"><pre><span></span>[&#39;god&#39;, &#39;saw&#39;, &#39;light&#39;, &#39;saw&#39;, &#39;good&#39;, &#39;god&#39;, &#39;divided&#39;, &#39;light&#39;, &#39;darkness&#39;]
</pre></div>


<div class="highlight"><pre><span></span><span class="n">texts</span> <span class="o">=</span> <span class="p">[</span><span class="n">text_preprocessing</span><span class="p">(</span><span class="n">passage</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">passage</span> <span class="ow">in</span> <span class="n">bible_data</span><span class="p">]</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">texts</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span>
</pre></div>


<div class="highlight"><pre><span></span>[&#39;god&#39;,
 &#39;said&#39;,
 &#39;let&#39;,
 &#39;expanse&#39;,
 &#39;middle&#39;,
 &#39;waters&#39;,
 &#39;let&#39;,
 &#39;divide&#39;,
 &#39;waters&#39;,
 &#39;waters&#39;]
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># Create a dictionary from our processed bible texts</span>

<span class="kn">from</span> <span class="nn">gensim</span> <span class="kn">import</span> <span class="n">corpora</span>

<span class="c1"># Create a dictionary that maps numbers to words</span>
<span class="n">dictionary</span> <span class="o">=</span> <span class="n">corpora</span><span class="o">.</span><span class="n">Dictionary</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span>
<span class="c1"># Save dictionary</span>
<span class="n">dictionary</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;bible.dict&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">dictionary</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>2018-06-21 12:50:20,527 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2018-06-21 12:50:20,799 : INFO : adding document #10000 to Dictionary(6375 unique tokens: [&#39;beginning&#39;, &#39;created&#39;, &#39;earth&#39;, &#39;god&#39;, &#39;heavens&#39;]...)
2018-06-21 12:50:21,016 : INFO : adding document #20000 to Dictionary(9840 unique tokens: [&#39;beginning&#39;, &#39;created&#39;, &#39;earth&#39;, &#39;god&#39;, &#39;heavens&#39;]...)
2018-06-21 12:50:21,242 : INFO : adding document #30000 to Dictionary(12041 unique tokens: [&#39;beginning&#39;, &#39;created&#39;, &#39;earth&#39;, &#39;god&#39;, &#39;heavens&#39;]...)
2018-06-21 12:50:21,272 : INFO : built Dictionary(12255 unique tokens: [&#39;beginning&#39;, &#39;created&#39;, &#39;earth&#39;, &#39;god&#39;, &#39;heavens&#39;]...) from 31102 documents (total 370556 corpus positions)
2018-06-21 12:50:21,276 : INFO : saving Dictionary object under bible.dict, separately None
2018-06-21 12:50:21,288 : INFO : saved bible.dict


Dictionary(12255 unique tokens: [&#39;beginning&#39;, &#39;created&#39;, &#39;earth&#39;, &#39;god&#39;, &#39;heavens&#39;]...)
</pre></div>


<div class="highlight"><pre><span></span><span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">dictionary</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">]</span>
<span class="c1"># Save corpus for later</span>
<span class="n">corpora</span><span class="o">.</span><span class="n">MmCorpus</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="s1">&#39;bible.mm&#39;</span><span class="p">,</span> <span class="n">corpus</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>2018-06-21 12:50:26,077 : INFO : storing corpus in Matrix Market format to bible.mm
2018-06-21 12:50:26,082 : INFO : saving sparse matrix to bible.mm
2018-06-21 12:50:26,085 : INFO : PROGRESS: saving document #0
2018-06-21 12:50:26,122 : INFO : PROGRESS: saving document #1000
...
2018-06-21 12:50:27,252 : INFO : PROGRESS: saving document #31000
2018-06-21 12:50:27,259 : INFO : saved 31102x12255 matrix, density=0.089% (339121/381155010)
2018-06-21 12:50:27,262 : INFO : saving MmCorpus index to bible.mm.index
IOPub data rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_data_rate_limit`.

Current values:
NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)
NotebookApp.rate_limit_window=3.0 (secs)
</pre></div>


<p>On a first run of this we note that most topics are defined by common stopwords. Let's get rid of these.</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">gensim</span> <span class="kn">import</span> <span class="n">models</span><span class="p">,</span> <span class="n">similarities</span>
<span class="c1"># We&#39;ll start with LSI and a 100D vector</span>
<span class="n">lsi</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">LsiModel</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">id2word</span><span class="o">=</span><span class="n">dictionary</span><span class="p">,</span> <span class="n">num_topics</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>2018-06-21 12:51:15,457 : INFO : using serial LSI version on this node
2018-06-21 12:51:15,458 : INFO : updating model with new documents
2018-06-21 12:51:15,460 : INFO : preparing a new chunk of documents
2018-06-21 12:51:15,620 : INFO : using 100 extra samples and 2 power iterations
2018-06-21 12:51:15,626 : INFO : 1st phase: constructing (12255, 200) action matrix
2018-06-21 12:51:15,866 : INFO : orthonormalizing (12255, 200) action matrix
2018-06-21 12:51:16,872 : INFO : 2nd phase: running dense svd on (200, 20000) matrix
2018-06-21 12:51:18,142 : INFO : computing the final decomposition
2018-06-21 12:51:18,146 : INFO : keeping 100 factors (discarding 18.228% of energy spectrum)
2018-06-21 12:51:18,326 : INFO : processed documents up to #20000
2018-06-21 12:51:18,329 : INFO : topic #0(128.237): 0.579*&quot;shall&quot; + 0.450*&quot;yahweh&quot; + 0.419*&quot;i&quot; + 0.176*&quot;said&quot; + 0.173*&quot;god&quot; + 0.131*&quot;israel&quot; + 0.108*&quot;king&quot; + 0.106*&quot;the&quot; + 0.087*&quot;he&quot; + 0.085*&quot;house&quot;
2018-06-21 12:51:18,333 : INFO : topic #1(94.911): -0.741*&quot;shall&quot; + 0.569*&quot;i&quot; + 0.178*&quot;yahweh&quot; + 0.174*&quot;said&quot; + 0.089*&quot;king&quot; + 0.081*&quot;god&quot; + 0.069*&quot;israel&quot; + -0.056*&quot;you&quot; + 0.049*&quot;son&quot; + -0.045*&quot;offering&quot;
2018-06-21 12:51:18,336 : INFO : topic #2(83.248): 0.656*&quot;i&quot; + -0.593*&quot;yahweh&quot; + 0.255*&quot;shall&quot; + -0.159*&quot;israel&quot; + -0.158*&quot;god&quot; + -0.138*&quot;king&quot; + -0.103*&quot;the&quot; + -0.081*&quot;house&quot; + -0.081*&quot;children&quot; + -0.076*&quot;son&quot;
2018-06-21 12:51:18,338 : INFO : topic #3(70.173): -0.513*&quot;yahweh&quot; + 0.490*&quot;king&quot; + 0.355*&quot;son&quot; + 0.249*&quot;the&quot; + 0.243*&quot;said&quot; + 0.167*&quot;israel&quot; + 0.139*&quot;he&quot; + -0.124*&quot;i&quot; + 0.117*&quot;children&quot; + 0.107*&quot;men&quot;
2018-06-21 12:51:18,342 : INFO : topic #4(57.722): 0.504*&quot;said&quot; + -0.451*&quot;son&quot; + -0.379*&quot;children&quot; + -0.349*&quot;israel&quot; + 0.339*&quot;he&quot; + -0.131*&quot;i&quot; + 0.129*&quot;let&quot; + 0.118*&quot;us&quot; + 0.109*&quot;go&quot; + 0.108*&quot;god&quot;
2018-06-21 12:51:18,345 : INFO : preparing a new chunk of documents
2018-06-21 12:51:18,454 : INFO : using 100 extra samples and 2 power iterations
2018-06-21 12:51:18,460 : INFO : 1st phase: constructing (12255, 200) action matrix
2018-06-21 12:51:18,589 : INFO : orthonormalizing (12255, 200) action matrix
2018-06-21 12:51:19,492 : INFO : 2nd phase: running dense svd on (200, 11102) matrix
2018-06-21 12:51:20,134 : INFO : computing the final decomposition
2018-06-21 12:51:20,138 : INFO : keeping 100 factors (discarding 19.942% of energy spectrum)
2018-06-21 12:51:20,313 : INFO : merging projections: (12255, 100) + (12255, 100)
2018-06-21 12:51:20,720 : INFO : keeping 100 factors (discarding 5.936% of energy spectrum)
2018-06-21 12:51:20,956 : INFO : processed documents up to #31102
2018-06-21 12:51:20,961 : INFO : topic #0(152.944): 0.600*&quot;i&quot; + 0.513*&quot;shall&quot; + 0.354*&quot;yahweh&quot; + 0.169*&quot;said&quot; + 0.157*&quot;god&quot; + 0.104*&quot;israel&quot; + 0.092*&quot;the&quot; + 0.082*&quot;king&quot; + 0.082*&quot;he&quot; + 0.075*&quot;land&quot;
2018-06-21 12:51:20,965 : INFO : topic #1(116.465): -0.735*&quot;shall&quot; + 0.651*&quot;i&quot; + 0.093*&quot;said&quot; + -0.062*&quot;yahweh&quot; + -0.050*&quot;you&quot; + -0.049*&quot;offering&quot; + -0.038*&quot;the&quot; + -0.025*&quot;priest&quot; + 0.023*&quot;know&quot; + 0.021*&quot;for&quot;
2018-06-21 12:51:20,966 : INFO : topic #2(97.426): 0.592*&quot;yahweh&quot; + -0.415*&quot;i&quot; + -0.394*&quot;shall&quot; + 0.258*&quot;god&quot; + 0.177*&quot;said&quot; + 0.167*&quot;israel&quot; + 0.167*&quot;king&quot; + 0.144*&quot;the&quot; + 0.118*&quot;son&quot; + 0.107*&quot;house&quot;
2018-06-21 12:51:20,968 : INFO : topic #3(79.928): -0.604*&quot;yahweh&quot; + 0.379*&quot;said&quot; + 0.303*&quot;king&quot; + 0.284*&quot;son&quot; + 0.245*&quot;the&quot; + 0.245*&quot;he&quot; + 0.145*&quot;man&quot; + 0.144*&quot;one&quot; + 0.096*&quot;came&quot; + -0.095*&quot;i&quot;
2018-06-21 12:51:20,974 : INFO : topic #4(69.851): 0.857*&quot;god&quot; + -0.237*&quot;king&quot; + -0.213*&quot;yahweh&quot; + -0.165*&quot;son&quot; + -0.162*&quot;the&quot; + -0.105*&quot;israel&quot; + 0.103*&quot;us&quot; + -0.093*&quot;children&quot; + 0.077*&quot;for&quot; + 0.064*&quot;jesus&quot;
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># Create index</span>
<span class="n">index</span> <span class="o">=</span> <span class="n">similarities</span><span class="o">.</span><span class="n">MatrixSimilarity</span><span class="p">(</span><span class="n">lsi</span><span class="p">[</span><span class="n">corpus</span><span class="p">])</span>
<span class="n">index</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;bible.index&#39;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>2018-06-21 12:53:38,112 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2018-06-21 12:53:39,874 : INFO : creating matrix with 31102 documents and 100 features
2018-06-21 12:53:43,628 : INFO : saving MatrixSimilarity object under bible.index, separately None
2018-06-21 12:53:43,786 : INFO : saved bible.index
</pre></div>


<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">text2vec</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">lsi</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Convert a portion of text to an LSI vector.&quot;&quot;&quot;</span>
    <span class="n">processed</span> <span class="o">=</span> <span class="n">text_preprocessing</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">vec_bow</span> <span class="o">=</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">processed</span><span class="p">)</span>
    <span class="n">vec_lsi</span> <span class="o">=</span> <span class="n">lsi</span><span class="p">[</span><span class="n">vec_bow</span><span class="p">]</span> <span class="c1"># convert the query to LSI space</span>
    <span class="k">return</span> <span class="n">vec_lsi</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">vec_lsi</span> <span class="o">=</span> <span class="n">text2vec</span><span class="p">(</span><span class="n">tweets</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">lsi</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">sims</span> <span class="o">=</span> <span class="n">index</span><span class="p">[</span><span class="n">vec_lsi</span><span class="p">]</span> <span class="c1"># perform a similarity query against the corpus</span>
<span class="k">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">sims</span><span class="p">))[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">])</span> <span class="c1"># print (document_number, document_similarity) 2-tuples</span>
</pre></div>


<div class="highlight"><pre><span></span>[(0, 0.026685458), (1, 0.010693545), (2, 0.02526992), (3, 0.018537477), (4, -0.0064496454)]
</pre></div>


<div class="highlight"><pre><span></span><span class="n">sims_sorted</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">sims</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">item</span><span class="p">:</span> <span class="o">-</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">sims_sorted</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">])</span> <span class="c1"># print sorted (document number, similarity score) 2-tuples</span>
</pre></div>


<div class="highlight"><pre><span></span>[(14471, 0.98052335), (16335, 0.78113711), (5388, 0.75273919), (17916, 0.74159586), (26053, 0.73570257)]
</pre></div>


<div class="highlight"><pre><span></span><span class="n">bible_data</span><span class="p">[</span><span class="n">sims_sorted</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]]</span>
</pre></div>


<div class="highlight"><pre><span></span>(&#39;Psalm 37:21&#39;,
 &quot;The wicked borrow, and don&#39;t pay back, but the righteous give generously.&quot;)
</pre></div>


<div class="highlight"><pre><span></span><span class="n">tweets</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span>
</pre></div>


<div class="highlight"><pre><span></span>&#39;“The ungovernable metropolis, with its fluid population and ethnic and occupational enclaves, is an affront to a mindset that envisions a world of harmony, purity, and organic wholeness.” - to thrive you need to give up unattainable perfection and unquestioning agreement&#39;
</pre></div>


<p>Now let's fold all this into a function.</p>
<div class="highlight"><pre><span></span><span class="n">zipped</span> <span class="o">=</span> <span class="p">[(</span><span class="n">p</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">v</span><span class="p">),</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">bible_data</span><span class="p">,</span> <span class="n">sims</span><span class="p">)]</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">zipped</span><span class="p">[</span><span class="mi">14471</span><span class="p">]</span>
</pre></div>


<div class="highlight"><pre><span></span>(&#39;Psalm 37:21&#39;,
 &quot;The wicked borrow, and don&#39;t pay back, but the righteous give generously.&quot;,
 0.98052335)
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># Import gensim modules</span>
<span class="kn">from</span> <span class="nn">gensim</span> <span class="kn">import</span> <span class="n">corpora</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">similarities</span>

<span class="c1"># Import NLTK modules</span>
<span class="kn">from</span> <span class="nn">nltk</span> <span class="kn">import</span> <span class="n">word_tokenize</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="c1"># Load stopwords</span>
<span class="n">ENG_STOPWORDS</span> <span class="o">=</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">text_preprocessing</span><span class="p">(</span><span class="n">original_text</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Clean and process texts for Gensim methods.&quot;&quot;&quot;</span>
    <span class="c1"># Tokenise</span>
    <span class="n">tokenised</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">original_text</span><span class="p">)</span>

    <span class="c1"># Convert to lowercase and remove non-text / stopwords</span>
    <span class="n">tokenised</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">tokenised</span> <span class="k">if</span> <span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()</span> <span class="ow">and</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ENG_STOPWORDS</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">tokenised</span>

<span class="k">def</span> <span class="nf">text2vec</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">lsi</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Convert a portion of text to an LSI vector.&quot;&quot;&quot;</span>
    <span class="n">processed</span> <span class="o">=</span> <span class="n">text_preprocessing</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">vec_bow</span> <span class="o">=</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">processed</span><span class="p">)</span>
    <span class="n">vec_lsi</span> <span class="o">=</span> <span class="n">lsi</span><span class="p">[</span><span class="n">vec_bow</span><span class="p">]</span> <span class="c1"># convert the query to LSI space</span>
    <span class="k">return</span> <span class="n">vec_lsi</span>

<span class="k">def</span> <span class="nf">build_data</span><span class="p">(</span><span class="n">tweets</span><span class="p">,</span> <span class="n">bible_data</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generate variables for matching.&quot;&quot;&quot;</span>
    <span class="c1"># Process text</span>
    <span class="n">texts</span> <span class="o">=</span> <span class="p">[</span><span class="n">text_preprocessing</span><span class="p">(</span><span class="n">passage</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">passage</span> <span class="ow">in</span> <span class="n">bible_data</span><span class="p">]</span>
    <span class="c1"># Build dictionary</span>
    <span class="n">dictionary</span> <span class="o">=</span> <span class="n">corpora</span><span class="o">.</span><span class="n">Dictionary</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span>
    <span class="c1"># Convert bible data to corpus</span>
    <span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">dictionary</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">]</span>
    <span class="n">lsi</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">LsiModel</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">id2word</span><span class="o">=</span><span class="n">dictionary</span><span class="p">,</span> <span class="n">num_topics</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="c1"># Create index</span>
    <span class="n">index</span> <span class="o">=</span> <span class="n">similarities</span><span class="o">.</span><span class="n">MatrixSimilarity</span><span class="p">(</span><span class="n">lsi</span><span class="p">[</span><span class="n">corpus</span><span class="p">])</span>
    <span class="c1"># Save all of these</span>
    <span class="n">dictionary</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;bible.dict&#39;</span><span class="p">)</span>
    <span class="n">corpora</span><span class="o">.</span><span class="n">MmCorpus</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="s1">&#39;bible.mm&#39;</span><span class="p">,</span> <span class="n">corpus</span><span class="p">)</span>
    <span class="n">lsi</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;bible.lsi&#39;</span><span class="p">)</span>
    <span class="n">index</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;bible.index&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">corpus</span><span class="p">,</span> <span class="n">lsi</span><span class="p">,</span> <span class="n">index</span>

<span class="k">def</span> <span class="nf">get_matches</span><span class="p">(</span><span class="n">tweet</span><span class="p">,</span> <span class="n">bible_data</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">lsi</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Match a tweet against the bible_data.&quot;&quot;&quot;</span>
    <span class="c1"># To run this we need dictionary, lsi, and index variables</span>
    <span class="c1"># Get matches</span>
    <span class="n">vec_lsi</span> <span class="o">=</span> <span class="n">text2vec</span><span class="p">(</span><span class="n">tweet</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">lsi</span><span class="p">)</span>
    <span class="n">sims</span> <span class="o">=</span> <span class="n">index</span><span class="p">[</span><span class="n">vec_lsi</span><span class="p">]</span> <span class="c1"># perform a similarity query against the corpus</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">[(</span><span class="n">p</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">v</span><span class="p">),</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">bible_data</span><span class="p">,</span> <span class="n">sims</span><span class="p">)]</span>
    <span class="c1"># Sort by descending score</span>
    <span class="n">scores</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">tup</span><span class="p">:</span> <span class="n">tup</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">reverse</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">scores</span>

<span class="k">def</span> <span class="nf">test_random_tweets</span><span class="p">(</span><span class="n">tweets</span><span class="p">,</span> <span class="n">bible_data</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Print n examples for k tweets selected at random.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">dictionary</span> <span class="o">=</span> <span class="n">corpora</span><span class="o">.</span><span class="n">Dictionary</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;bible.dict&#39;</span><span class="p">)</span>
        <span class="n">corpus</span> <span class="o">=</span> <span class="n">corpora</span><span class="o">.</span><span class="n">MmCorpus</span><span class="p">(</span><span class="s1">&#39;bible.mm&#39;</span><span class="p">)</span>
        <span class="n">lsi</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">LsiModel</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;bible.lsi&#39;</span><span class="p">)</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">similarities</span><span class="o">.</span><span class="n">MatrixSimilarity</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;bible.index&#39;</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">FileNotFoundError</span><span class="p">:</span>
        <span class="n">dictionary</span><span class="p">,</span> <span class="n">corpus</span><span class="p">,</span> <span class="n">lsi</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="n">build_data</span><span class="p">(</span><span class="n">tweets</span><span class="p">,</span> <span class="n">bible_data</span><span class="p">)</span>

    <span class="kn">import</span> <span class="nn">random</span>
    <span class="n">num_tweets</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tweets</span><span class="p">)</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_tweets</span><span class="p">),</span> <span class="n">k</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>
        <span class="n">tweet</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;-----------------&quot;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Tweet text: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tweet</span><span class="p">))</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">get_matches</span><span class="p">(</span><span class="n">tweet</span><span class="p">,</span> <span class="n">bible_data</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">lsi</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">verse</span><span class="p">,</span> <span class="n">passage</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">n</span><span class="p">]:</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">{0}, {1}, {2}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">verse</span><span class="p">,</span> <span class="n">passage</span><span class="p">,</span> <span class="n">score</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="nt">2018-06-23</span> <span class="nt">08</span><span class="p">:</span><span class="nd">15</span><span class="p">:</span><span class="nd">34</span><span class="o">,</span><span class="nt">349</span> <span class="o">:</span> <span class="nt">INFO</span> <span class="o">:</span> <span class="s1">&#39;pattern&#39;</span> <span class="nt">package</span> <span class="nt">not</span> <span class="nt">found</span><span class="o">;</span> <span class="nt">tag</span> <span class="nt">filters</span> <span class="nt">are</span> <span class="nt">not</span> <span class="nt">available</span> <span class="nt">for</span> <span class="nt">English</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">test_random_tweets</span><span class="p">(</span><span class="n">tweets</span><span class="p">,</span> <span class="n">bible_data</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>2018-06-21 13:41:59,527 : INFO : loading Dictionary object from bible.dict
2018-06-21 13:41:59,541 : INFO : loaded bible.dict
2018-06-21 13:41:59,552 : INFO : loaded corpus index from bible.mm.index
2018-06-21 13:41:59,557 : INFO : initializing cython corpus reader from bible.mm
2018-06-21 13:41:59,562 : INFO : accepted corpus with 31102 documents, 12255 features, 339121 non-zero entries
2018-06-21 13:41:59,564 : INFO : loading LsiModel object from bible.lsi
2018-06-21 13:42:09,193 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2018-06-21 13:42:09,432 : INFO : adding document #10000 to Dictionary(6375 unique tokens: [&#39;beginning&#39;, &#39;created&#39;, &#39;earth&#39;, &#39;god&#39;, &#39;heavens&#39;]...)
2018-06-21 13:42:09,651 : INFO : adding document #20000 to Dictionary(9840 unique tokens: [&#39;beginning&#39;, &#39;created&#39;, &#39;earth&#39;, &#39;god&#39;, &#39;heavens&#39;]...)
2018-06-21 13:42:09,875 : INFO : adding document #30000 to Dictionary(12041 unique tokens: [&#39;beginning&#39;, &#39;created&#39;, &#39;earth&#39;, &#39;god&#39;, &#39;heavens&#39;]...)
2018-06-21 13:42:09,905 : INFO : built Dictionary(12255 unique tokens: [&#39;beginning&#39;, &#39;created&#39;, &#39;earth&#39;, &#39;god&#39;, &#39;heavens&#39;]...) from 31102 documents (total 370556 corpus positions)
2018-06-21 13:42:10,369 : INFO : using serial LSI version on this node
2018-06-21 13:42:10,372 : INFO : updating model with new documents
2018-06-21 13:42:10,375 : INFO : preparing a new chunk of documents
2018-06-21 13:42:10,533 : INFO : using 100 extra samples and 2 power iterations
2018-06-21 13:42:10,536 : INFO : 1st phase: constructing (12255, 200) action matrix
2018-06-21 13:42:10,752 : INFO : orthonormalizing (12255, 200) action matrix
2018-06-21 13:42:11,558 : INFO : 2nd phase: running dense svd on (200, 20000) matrix
2018-06-21 13:42:12,703 : INFO : computing the final decomposition
2018-06-21 13:42:12,707 : INFO : keeping 100 factors (discarding 18.237% of energy spectrum)
2018-06-21 13:42:12,892 : INFO : processed documents up to #20000
2018-06-21 13:42:12,900 : INFO : topic #0(128.237): 0.579*&quot;shall&quot; + 0.450*&quot;yahweh&quot; + 0.419*&quot;i&quot; + 0.176*&quot;said&quot; + 0.173*&quot;god&quot; + 0.131*&quot;israel&quot; + 0.108*&quot;king&quot; + 0.106*&quot;the&quot; + 0.087*&quot;he&quot; + 0.085*&quot;house&quot;
2018-06-21 13:42:12,906 : INFO : topic #1(94.911): -0.741*&quot;shall&quot; + 0.569*&quot;i&quot; + 0.178*&quot;yahweh&quot; + 0.174*&quot;said&quot; + 0.089*&quot;king&quot; + 0.081*&quot;god&quot; + 0.069*&quot;israel&quot; + -0.056*&quot;you&quot; + 0.049*&quot;son&quot; + -0.045*&quot;offering&quot;
2018-06-21 13:42:12,910 : INFO : topic #2(83.248): -0.656*&quot;i&quot; + 0.593*&quot;yahweh&quot; + -0.255*&quot;shall&quot; + 0.159*&quot;israel&quot; + 0.158*&quot;god&quot; + 0.138*&quot;king&quot; + 0.103*&quot;the&quot; + 0.081*&quot;house&quot; + 0.081*&quot;children&quot; + 0.076*&quot;son&quot;
2018-06-21 13:42:12,913 : INFO : topic #3(70.173): -0.513*&quot;yahweh&quot; + 0.490*&quot;king&quot; + 0.355*&quot;son&quot; + 0.249*&quot;the&quot; + 0.243*&quot;said&quot; + 0.167*&quot;israel&quot; + 0.139*&quot;he&quot; + -0.124*&quot;i&quot; + 0.117*&quot;children&quot; + 0.107*&quot;men&quot;
2018-06-21 13:42:12,919 : INFO : topic #4(57.722): -0.504*&quot;said&quot; + 0.451*&quot;son&quot; + 0.379*&quot;children&quot; + 0.350*&quot;israel&quot; + -0.339*&quot;he&quot; + 0.131*&quot;i&quot; + -0.129*&quot;let&quot; + -0.118*&quot;us&quot; + -0.109*&quot;go&quot; + -0.108*&quot;god&quot;
2018-06-21 13:42:12,922 : INFO : preparing a new chunk of documents
2018-06-21 13:42:13,026 : INFO : using 100 extra samples and 2 power iterations
2018-06-21 13:42:13,031 : INFO : 1st phase: constructing (12255, 200) action matrix
2018-06-21 13:42:13,162 : INFO : orthonormalizing (12255, 200) action matrix
2018-06-21 13:42:14,004 : INFO : 2nd phase: running dense svd on (200, 11102) matrix
2018-06-21 13:42:14,555 : INFO : computing the final decomposition
2018-06-21 13:42:14,558 : INFO : keeping 100 factors (discarding 20.022% of energy spectrum)
2018-06-21 13:42:14,734 : INFO : merging projections: (12255, 100) + (12255, 100)
2018-06-21 13:42:15,064 : INFO : keeping 100 factors (discarding 5.910% of energy spectrum)
2018-06-21 13:42:15,312 : INFO : processed documents up to #31102
2018-06-21 13:42:15,316 : INFO : topic #0(152.944): 0.600*&quot;i&quot; + 0.513*&quot;shall&quot; + 0.354*&quot;yahweh&quot; + 0.169*&quot;said&quot; + 0.157*&quot;god&quot; + 0.104*&quot;israel&quot; + 0.092*&quot;the&quot; + 0.082*&quot;king&quot; + 0.082*&quot;he&quot; + 0.075*&quot;land&quot;
2018-06-21 13:42:15,322 : INFO : topic #1(116.465): -0.735*&quot;shall&quot; + 0.651*&quot;i&quot; + 0.093*&quot;said&quot; + -0.062*&quot;yahweh&quot; + -0.050*&quot;you&quot; + -0.049*&quot;offering&quot; + -0.038*&quot;the&quot; + -0.025*&quot;priest&quot; + 0.023*&quot;know&quot; + 0.021*&quot;for&quot;
2018-06-21 13:42:15,325 : INFO : topic #2(97.426): 0.592*&quot;yahweh&quot; + -0.415*&quot;i&quot; + -0.394*&quot;shall&quot; + 0.258*&quot;god&quot; + 0.177*&quot;said&quot; + 0.167*&quot;israel&quot; + 0.167*&quot;king&quot; + 0.144*&quot;the&quot; + 0.118*&quot;son&quot; + 0.107*&quot;house&quot;
2018-06-21 13:42:15,328 : INFO : topic #3(79.927): -0.604*&quot;yahweh&quot; + 0.379*&quot;said&quot; + 0.303*&quot;king&quot; + 0.284*&quot;son&quot; + 0.245*&quot;the&quot; + 0.245*&quot;he&quot; + 0.145*&quot;man&quot; + 0.144*&quot;one&quot; + 0.096*&quot;came&quot; + -0.095*&quot;i&quot;
2018-06-21 13:42:15,330 : INFO : topic #4(69.851): 0.857*&quot;god&quot; + -0.237*&quot;king&quot; + -0.213*&quot;yahweh&quot; + -0.164*&quot;son&quot; + -0.162*&quot;the&quot; + -0.105*&quot;israel&quot; + 0.103*&quot;us&quot; + -0.093*&quot;children&quot; + 0.077*&quot;for&quot; + 0.064*&quot;jesus&quot;
2018-06-21 13:42:15,337 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2018-06-21 13:42:16,933 : INFO : creating matrix with 31102 documents and 100 features
2018-06-21 13:42:20,744 : INFO : saving Dictionary object under bible.dict, separately None
2018-06-21 13:42:20,756 : INFO : saved bible.dict
2018-06-21 13:42:20,762 : INFO : storing corpus in Matrix Market format to bible.mm
2018-06-21 13:42:20,768 : INFO : saving sparse matrix to bible.mm
2018-06-21 13:42:20,770 : INFO : PROGRESS: saving document #0
2018-06-21 13:42:20,809 : INFO : PROGRESS: saving document #1000
...
2018-06-21 13:42:21,970 : INFO : PROGRESS: saving document #31000
2018-06-21 13:42:21,977 : INFO : saved 31102x12255 matrix, density=0.089% (339121/381155010)
2018-06-21 13:42:21,980 : INFO : saving MmCorpus index to bible.mm.index
2018-06-21 13:42:21,985 : INFO : saving Projection object under bibl.lsi.projection, separately None
2018-06-21 13:42:22,092 : INFO : saved bibl.lsi.projection
2018-06-21 13:42:22,096 : INFO : saving LsiModel object under bibl.lsi, separately None
2018-06-21 13:42:22,098 : INFO : not storing attribute projection
2018-06-21 13:42:22,101 : INFO : not storing attribute dispatcher
2018-06-21 13:42:22,110 : INFO : saved bibl.lsi
2018-06-21 13:42:22,115 : INFO : saving MatrixSimilarity object under bible.index, separately None
2018-06-21 13:42:22,250 : INFO : saved bible.index
</pre></div>


<div class="highlight"><pre><span></span>-----------------
Tweet text: @sustrans Kids to Newbridge primary in Bath have river cycle path close - but no safe way to travel 200m up hill &amp; across A-road or to path

Genesis 49:17, Dan will be a serpent in the way, an adder in the path, That bites the horse&#39;s heels, so that his rider falls backward., 0.9940089583396912

Psalm 80:12, Why have you broken down its walls, so that all those who pass by the way pluck it?, 0.9881158471107483

Proverbs 13:6, Righteousness guards the way of integrity, but wickedness overthrows the sinner., 0.9859569668769836

Genesis 35:19, Rachel died, and was buried in the way to Ephrath (the same is Bethlehem)., 0.9790574312210083

Ezekiel 12:5, Dig through the wall in their sight, and carry your stuff out that way., 0.9741089344024658
-----------------
Tweet text: Stand-Up Comics Have to Censor Their Jokes on (US) College Campuses - The Atlantic http://t.co/W998v8oahs

Lamentations 5:16, The crown is fallen from our head: Woe to us! for we have sinned., 0.9783570766448975

Acts 28:2, The natives showed us uncommon kindness; for they kindled a fire, and received us all, because of the present rain, and because of the cold., 0.9126466512680054

Deuteronomy 26:6, The Egyptians dealt ill with us, and afflicted us, and laid on us hard bondage:, 0.89407879114151

Ezra 4:18, The letter which you sent to us has been plainly read before me., 0.863696277141571

Judges 9:12, The trees said to the vine, &#39;Come and reign over us.&#39;, 0.8148699998855591
-----------------
Tweet text: Ha - was just reminded of the 90s Internet time limits, e.g. 5 hours online per week. Could do with that now.

Ecclesiastes 3:4, a time to weep, and a time to laugh; a time to mourn, and a time to dance;, 0.9986615180969238

Ecclesiastes 3:3, a time to kill, and a time to heal; a time to break down, and a time to build up;, 0.9981067180633545

Matthew 26:16, From that time he sought opportunity to betray him., 0.9979551434516907

Ecclesiastes 3:2, a time to be born, and a time to die; a time to plant, and a time to pluck up that which is planted;, 0.9977869987487793

Hebrews 9:10, being only (with meats and drinks and various washings) fleshly ordinances, imposed until a time of reformation., 0.9975525736808777
-----------------
Tweet text: Here&#39;s What Happened To All 53 of Marissa Mayer&#39;s Yahoo Acquisitions https://t.co/0YT2TXncHN

Luke 24:51, It happened, while he blessed them, that he withdrew from them, and was carried up into heaven., 0.8907666802406311

Joshua 5:8, It happened, when they were done circumcising all the nation, that they stayed in their places in the camp until they were healed., 0.8737368583679199

1 Kings 15:21, It happened, when Baasha heard of it, that he left off building Ramah, and lived in Tirzah., 0.8584436178207397

Joshua 19:26, Allammelech, Amad, Mishal. It reached to Carmel westward, and to Shihorlibnath., 0.8564523458480835

2 Corinthians 9:1, It is indeed unnecessary for me to write to you concerning the service to the saints,, 0.852521538734436
-----------------
Tweet text: Even with more complex deep architectures you can get a surprising amount done with simple ngram approaches - a future in hybrids? https://t.co/jD3pIhnIbP

Daniel 9:5, we have sinned, and have dealt perversely, and have done wickedly, and have rebelled, even turning aside from your precepts and from your ordinances;, 0.9942108988761902

Ephesians 5:11, Have no fellowship with the unfruitful works of darkness, but rather even reprove them., 0.9036127924919128

Joshua 10:41, Joshua struck them from Kadesh Barnea even to Gaza, and all the country of Goshen, even to Gibeon., 0.885510265827179

Numbers 21:30, We have shot at them. Heshbon has perished even to Dibon. We have laid waste even to Nophah, Which reaches to Medeba., 0.8847762942314148

Deuteronomy 4:48, from Aroer, which is on the edge of the valley of the Arnon, even to Mount Sion (the same is Hermon),, 0.882093071937561
</pre></div>


<h3>Comparing Approaches</h3>
<p>To compare the approaches, let's generate 200 random examples and take the top match for each of the three techniques. We will then manually score each match on a scale of 0 to 5 where 0 = no match and 5 = perfect match. Then we can see which technique comes up on top.</p>
<p>The easiest way to quickly compare the results is to export to a spreadsheet, with columns for the scores of each.</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_difflib_matches</span><span class="p">(</span><span class="n">tweet</span><span class="p">,</span> <span class="n">bible_data</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Match a tweet against the bible_data.&quot;&quot;&quot;</span>
    <span class="c1"># Get matches</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="n">verse</span><span class="p">,</span> <span class="n">passage</span><span class="p">,</span> <span class="n">SequenceMatcher</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="n">tweet</span><span class="p">,</span> <span class="n">passage</span><span class="p">)</span><span class="o">.</span><span class="n">ratio</span><span class="p">())</span>
        <span class="k">for</span> <span class="n">verse</span><span class="p">,</span> <span class="n">passage</span> <span class="ow">in</span> <span class="n">bible_data</span>
    <span class="p">]</span>
    <span class="c1"># Sort by descending score</span>
    <span class="n">scores</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">tup</span><span class="p">:</span> <span class="n">tup</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">reverse</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">scores</span>

<span class="k">def</span> <span class="nf">get_spacy_matches</span><span class="p">(</span><span class="n">spacy_tweet</span><span class="p">,</span> <span class="n">spacy_bible</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Perform matches on text as spacy docs&quot;&quot;&quot;</span>
    <span class="c1"># Get matches</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="n">verse</span><span class="p">,</span> <span class="n">passage</span><span class="p">,</span> <span class="n">spacy_tweet</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="n">passage</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">verse</span><span class="p">,</span> <span class="n">passage</span> <span class="ow">in</span> <span class="n">spacy_bible</span>
    <span class="p">]</span>
    <span class="c1"># Sort by descending score</span>
    <span class="n">scores</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">tup</span><span class="p">:</span> <span class="n">tup</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">reverse</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">scores</span>

<span class="k">def</span> <span class="nf">get_gensim_matches</span><span class="p">(</span><span class="n">tweet</span><span class="p">,</span> <span class="n">bible_data</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">lsi</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Match a tweet against the bible_data.&quot;&quot;&quot;</span>
    <span class="c1"># To run this we need dictionary, lsi, and index variables</span>
    <span class="c1"># Get matches</span>
    <span class="n">vec_lsi</span> <span class="o">=</span> <span class="n">text2vec</span><span class="p">(</span><span class="n">tweet</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">lsi</span><span class="p">)</span>
    <span class="n">sims</span> <span class="o">=</span> <span class="n">index</span><span class="p">[</span><span class="n">vec_lsi</span><span class="p">]</span> <span class="c1"># perform a similarity query against the corpus</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">[(</span><span class="n">v</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">bible_data</span><span class="p">,</span> <span class="n">sims</span><span class="p">)]</span>
    <span class="c1"># Sort by descending score</span>
    <span class="n">scores</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">tup</span><span class="p">:</span> <span class="n">tup</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">reverse</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">scores</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">spacy_bible</span> <span class="o">=</span> <span class="p">[(</span><span class="n">verse</span><span class="p">,</span> <span class="n">nlp</span><span class="p">(</span><span class="n">passage</span><span class="p">))</span> <span class="k">for</span> <span class="n">verse</span><span class="p">,</span> <span class="n">passage</span> <span class="ow">in</span> <span class="n">bible_data</span><span class="p">]</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">dictionary</span><span class="p">,</span> <span class="n">corpus</span><span class="p">,</span> <span class="n">lsi</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="n">build_data</span><span class="p">(</span><span class="n">tweets</span><span class="p">,</span> <span class="n">bible_data</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>2018-06-23 09:02:25,811 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2018-06-23 09:02:26,052 : INFO : adding document #10000 to Dictionary(6375 unique tokens: [&#39;beginning&#39;, &#39;created&#39;, &#39;earth&#39;, &#39;god&#39;, &#39;heavens&#39;]...)
2018-06-23 09:02:26,272 : INFO : adding document #20000 to Dictionary(9840 unique tokens: [&#39;beginning&#39;, &#39;created&#39;, &#39;earth&#39;, &#39;god&#39;, &#39;heavens&#39;]...)
2018-06-23 09:02:26,491 : INFO : adding document #30000 to Dictionary(12041 unique tokens: [&#39;beginning&#39;, &#39;created&#39;, &#39;earth&#39;, &#39;god&#39;, &#39;heavens&#39;]...)
2018-06-23 09:02:26,516 : INFO : built Dictionary(12255 unique tokens: [&#39;beginning&#39;, &#39;created&#39;, &#39;earth&#39;, &#39;god&#39;, &#39;heavens&#39;]...) from 31102 documents (total 370556 corpus positions)
2018-06-23 09:02:26,953 : INFO : using serial LSI version on this node
2018-06-23 09:02:26,954 : INFO : updating model with new documents
2018-06-23 09:02:26,955 : INFO : preparing a new chunk of documents
2018-06-23 09:02:27,111 : INFO : using 100 extra samples and 2 power iterations
2018-06-23 09:02:27,112 : INFO : 1st phase: constructing (12255, 200) action matrix
2018-06-23 09:02:27,349 : INFO : orthonormalizing (12255, 200) action matrix
2018-06-23 09:02:28,118 : INFO : 2nd phase: running dense svd on (200, 20000) matrix
2018-06-23 09:02:29,147 : INFO : computing the final decomposition
2018-06-23 09:02:29,161 : INFO : keeping 100 factors (discarding 18.228% of energy spectrum)
2018-06-23 09:02:29,352 : INFO : processed documents up to #20000
2018-06-23 09:02:29,357 : INFO : topic #0(128.237): 0.579*&quot;shall&quot; + 0.450*&quot;yahweh&quot; + 0.419*&quot;i&quot; + 0.176*&quot;said&quot; + 0.173*&quot;god&quot; + 0.131*&quot;israel&quot; + 0.108*&quot;king&quot; + 0.106*&quot;the&quot; + 0.087*&quot;he&quot; + 0.085*&quot;house&quot;
2018-06-23 09:02:29,359 : INFO : topic #1(94.911): 0.741*&quot;shall&quot; + -0.569*&quot;i&quot; + -0.178*&quot;yahweh&quot; + -0.174*&quot;said&quot; + -0.089*&quot;king&quot; + -0.081*&quot;god&quot; + -0.069*&quot;israel&quot; + 0.056*&quot;you&quot; + -0.049*&quot;son&quot; + 0.045*&quot;offering&quot;
2018-06-23 09:02:29,361 : INFO : topic #2(83.248): -0.656*&quot;i&quot; + 0.593*&quot;yahweh&quot; + -0.255*&quot;shall&quot; + 0.159*&quot;israel&quot; + 0.158*&quot;god&quot; + 0.138*&quot;king&quot; + 0.103*&quot;the&quot; + 0.081*&quot;house&quot; + 0.081*&quot;children&quot; + 0.076*&quot;son&quot;
2018-06-23 09:02:29,363 : INFO : topic #3(70.173): 0.513*&quot;yahweh&quot; + -0.490*&quot;king&quot; + -0.355*&quot;son&quot; + -0.249*&quot;the&quot; + -0.243*&quot;said&quot; + -0.167*&quot;israel&quot; + -0.139*&quot;he&quot; + 0.124*&quot;i&quot; + -0.117*&quot;children&quot; + -0.107*&quot;men&quot;
2018-06-23 09:02:29,365 : INFO : topic #4(57.722): 0.504*&quot;said&quot; + -0.451*&quot;son&quot; + -0.379*&quot;children&quot; + -0.350*&quot;israel&quot; + 0.339*&quot;he&quot; + -0.131*&quot;i&quot; + 0.129*&quot;let&quot; + 0.118*&quot;us&quot; + 0.109*&quot;go&quot; + 0.108*&quot;god&quot;
2018-06-23 09:02:29,367 : INFO : preparing a new chunk of documents
2018-06-23 09:02:29,467 : INFO : using 100 extra samples and 2 power iterations
2018-06-23 09:02:29,469 : INFO : 1st phase: constructing (12255, 200) action matrix
2018-06-23 09:02:29,587 : INFO : orthonormalizing (12255, 200) action matrix
2018-06-23 09:02:30,386 : INFO : 2nd phase: running dense svd on (200, 11102) matrix
2018-06-23 09:02:30,731 : INFO : computing the final decomposition
2018-06-23 09:02:30,732 : INFO : keeping 100 factors (discarding 19.942% of energy spectrum)
2018-06-23 09:02:30,935 : INFO : merging projections: (12255, 100) + (12255, 100)
2018-06-23 09:02:31,243 : INFO : keeping 100 factors (discarding 5.902% of energy spectrum)
2018-06-23 09:02:31,483 : INFO : processed documents up to #31102
2018-06-23 09:02:31,485 : INFO : topic #0(152.944): 0.600*&quot;i&quot; + 0.513*&quot;shall&quot; + 0.354*&quot;yahweh&quot; + 0.169*&quot;said&quot; + 0.157*&quot;god&quot; + 0.104*&quot;israel&quot; + 0.092*&quot;the&quot; + 0.082*&quot;king&quot; + 0.082*&quot;he&quot; + 0.075*&quot;land&quot;
2018-06-23 09:02:31,486 : INFO : topic #1(116.465): -0.735*&quot;shall&quot; + 0.651*&quot;i&quot; + 0.093*&quot;said&quot; + -0.062*&quot;yahweh&quot; + -0.050*&quot;you&quot; + -0.049*&quot;offering&quot; + -0.038*&quot;the&quot; + -0.025*&quot;priest&quot; + 0.023*&quot;know&quot; + 0.021*&quot;for&quot;
2018-06-23 09:02:31,487 : INFO : topic #2(97.426): 0.592*&quot;yahweh&quot; + -0.415*&quot;i&quot; + -0.394*&quot;shall&quot; + 0.258*&quot;god&quot; + 0.177*&quot;said&quot; + 0.167*&quot;israel&quot; + 0.167*&quot;king&quot; + 0.144*&quot;the&quot; + 0.118*&quot;son&quot; + 0.107*&quot;house&quot;
2018-06-23 09:02:31,489 : INFO : topic #3(79.928): -0.604*&quot;yahweh&quot; + 0.379*&quot;said&quot; + 0.303*&quot;king&quot; + 0.284*&quot;son&quot; + 0.245*&quot;the&quot; + 0.245*&quot;he&quot; + 0.145*&quot;man&quot; + 0.144*&quot;one&quot; + 0.096*&quot;came&quot; + -0.095*&quot;i&quot;
2018-06-23 09:02:31,491 : INFO : topic #4(69.852): 0.857*&quot;god&quot; + -0.237*&quot;king&quot; + -0.213*&quot;yahweh&quot; + -0.165*&quot;son&quot; + -0.162*&quot;the&quot; + -0.105*&quot;israel&quot; + 0.103*&quot;us&quot; + -0.093*&quot;children&quot; + 0.077*&quot;for&quot; + 0.064*&quot;jesus&quot;
2018-06-23 09:02:31,492 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2018-06-23 09:02:32,948 : INFO : creating matrix with 31102 documents and 100 features
2018-06-23 09:02:36,645 : INFO : saving Dictionary object under bible.dict, separately None
2018-06-23 09:02:36,713 : INFO : saved bible.dict
2018-06-23 09:02:36,714 : INFO : storing corpus in Matrix Market format to bible.mm
2018-06-23 09:02:36,715 : INFO : saving sparse matrix to bible.mm
2018-06-23 09:02:36,716 : INFO : PROGRESS: saving document #0
2018-06-23 09:02:36,753 : INFO : PROGRESS: saving document #1000
2018-06-23 09:02:36,789 : INFO : PROGRESS: saving document #2000
2018-06-23 09:02:36,832 : INFO : PROGRESS: saving document #3000
2018-06-23 09:02:36,863 : INFO : PROGRESS: saving document #4000
2018-06-23 09:02:36,898 : INFO : PROGRESS: saving document #5000
2018-06-23 09:02:36,933 : INFO : PROGRESS: saving document #6000
2018-06-23 09:02:36,970 : INFO : PROGRESS: saving document #7000
2018-06-23 09:02:37,005 : INFO : PROGRESS: saving document #8000
2018-06-23 09:02:37,041 : INFO : PROGRESS: saving document #9000
2018-06-23 09:02:37,081 : INFO : PROGRESS: saving document #10000
2018-06-23 09:02:37,123 : INFO : PROGRESS: saving document #11000
2018-06-23 09:02:37,169 : INFO : PROGRESS: saving document #12000
2018-06-23 09:02:37,200 : INFO : PROGRESS: saving document #13000
2018-06-23 09:02:37,224 : INFO : PROGRESS: saving document #14000
2018-06-23 09:02:37,251 : INFO : PROGRESS: saving document #15000
2018-06-23 09:02:37,277 : INFO : PROGRESS: saving document #16000
2018-06-23 09:02:37,311 : INFO : PROGRESS: saving document #17000
2018-06-23 09:02:37,350 : INFO : PROGRESS: saving document #18000
2018-06-23 09:02:37,386 : INFO : PROGRESS: saving document #19000
2018-06-23 09:02:37,421 : INFO : PROGRESS: saving document #20000
2018-06-23 09:02:37,453 : INFO : PROGRESS: saving document #21000
2018-06-23 09:02:37,488 : INFO : PROGRESS: saving document #22000
2018-06-23 09:02:37,522 : INFO : PROGRESS: saving document #23000
2018-06-23 09:02:37,563 : INFO : PROGRESS: saving document #24000
2018-06-23 09:02:37,591 : INFO : PROGRESS: saving document #25000
2018-06-23 09:02:37,621 : INFO : PROGRESS: saving document #26000
2018-06-23 09:02:37,648 : INFO : PROGRESS: saving document #27000
2018-06-23 09:02:37,680 : INFO : PROGRESS: saving document #28000
2018-06-23 09:02:37,719 : INFO : PROGRESS: saving document #29000
2018-06-23 09:02:37,758 : INFO : PROGRESS: saving document #30000
2018-06-23 09:02:37,790 : INFO : PROGRESS: saving document #31000
2018-06-23 09:02:37,795 : INFO : saved 31102x12255 matrix, density=0.089% (339121/381155010)
2018-06-23 09:02:37,797 : INFO : saving MmCorpus index to bible.mm.index
2018-06-23 09:02:37,799 : INFO : saving Projection object under bible.lsi.projection, separately None
2018-06-23 09:02:37,944 : INFO : saved bible.lsi.projection
2018-06-23 09:02:37,945 : INFO : saving LsiModel object under bible.lsi, separately None
2018-06-23 09:02:37,946 : INFO : not storing attribute projection
2018-06-23 09:02:37,947 : INFO : not storing attribute dispatcher
2018-06-23 09:02:37,953 : INFO : saved bible.lsi
2018-06-23 09:02:37,954 : INFO : saving MatrixSimilarity object under bible.index, separately None
2018-06-23 09:02:38,053 : INFO : saved bible.index
</pre></div>


<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>

<span class="n">rows</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">num_tweets</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tweets</span><span class="p">)</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_tweets</span><span class="p">),</span> <span class="n">k</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>
    <span class="n">tweet</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">dl_match</span> <span class="o">=</span> <span class="n">get_difflib_matches</span><span class="p">(</span><span class="n">tweet</span><span class="p">,</span> <span class="n">bible_data</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">spacy_tweet</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>
    <span class="n">sp_match</span> <span class="o">=</span> <span class="n">get_spacy_matches</span><span class="p">(</span><span class="n">spacy_tweet</span><span class="p">,</span> <span class="n">spacy_bible</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">gs_match</span> <span class="o">=</span> <span class="n">get_gensim_matches</span><span class="p">(</span><span class="n">tweet</span><span class="p">,</span> <span class="n">bible_data</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">lsi</span><span class="p">,</span> <span class="n">index</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">comparison_row</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">tweet</span><span class="p">,</span>
        <span class="n">dl_match</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dl_match</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">sp_match</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">sp_match</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">gs_match</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">gs_match</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="s2">&quot;&quot;</span>
    <span class="p">)</span>
    <span class="n">rows</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">comparison_row</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pickle</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;rows.pkl&quot;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>

<span class="n">row_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rows</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="k">del</span> <span class="n">rows</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">row_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Also: if your patent specification does not co...</td>
      <td>Therefore you need to be in subjection, not on...</td>
      <td>0.420168</td>
      <td></td>
      <td>But whatever has a blemish, that you shall not...</td>
      <td>0.921702</td>
      <td></td>
      <td>There is one body, and one Spirit, even as you...</td>
      <td>0.836346</td>
      <td></td>
    </tr>
    <tr>
      <th>1</th>
      <td>The CImg Library - C++ Template Image Processi...</td>
      <td>the people which I formed for myself, that the...</td>
      <td>0.374384</td>
      <td></td>
      <td>For the house he made windows of fixed lattice...</td>
      <td>0.736559</td>
      <td></td>
      <td>The sound of a cry from Horonaim, desolation a...</td>
      <td>0.971526</td>
      <td></td>
    </tr>
    <tr>
      <th>2</th>
      <td>Criteria for boilerplate legal text: it should...</td>
      <td>He began to build in the second [day] of the s...</td>
      <td>0.447368</td>
      <td></td>
      <td>It's also written in your law that the testimo...</td>
      <td>0.923304</td>
      <td></td>
      <td>the two pillars, and the two bowls of the capi...</td>
      <td>0.711855</td>
      <td></td>
    </tr>
    <tr>
      <th>3</th>
      <td>Hadn't realised: the difference between deduct...</td>
      <td>and the avenger of blood find him outside of t...</td>
      <td>0.386946</td>
      <td></td>
      <td>However in the assembly I would rather speak f...</td>
      <td>0.927348</td>
      <td></td>
      <td>Should he reason with unprofitable talk, or wi...</td>
      <td>0.997764</td>
      <td></td>
    </tr>
    <tr>
      <th>4</th>
      <td>You need to be wrong on certain things in orde...</td>
      <td>No eye pitied you, to do any of these things t...</td>
      <td>0.452830</td>
      <td></td>
      <td>Be of the same mind one toward another. Don't ...</td>
      <td>0.966708</td>
      <td></td>
      <td>You are witnesses of these things.</td>
      <td>0.823695</td>
      <td></td>
    </tr>
  </tbody>
</table>
</div>

<div class="highlight"><pre><span></span><span class="err">!</span><span class="n">pip3</span> <span class="n">install</span> <span class="n">xlwt</span>
</pre></div>


<div class="highlight"><pre><span></span>Collecting xlwt
[?25l  Downloading https://files.pythonhosted.org/packages/44/48/def306413b25c3d01753603b1a222a011b8621aed27cd7f89cbc27e6b0f4/xlwt-1.3.0-py2.py3-none-any.whl (99kB)
[K    100% |################################| 102kB 2.9MB/s a 0:00:011
[?25hInstalling collected packages: xlwt
Successfully installed xlwt-1.3.0
</pre></div>


<div class="highlight"><pre><span></span><span class="n">row_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s2">&quot;comparison.xls&quot;</span><span class="p">)</span>
</pre></div>
    </div>
    <hr/>
    <footer>
      <ul class="list-inline">
        <li class="list-inline-item text-muted" title="2018-06-25T10:24:16.697251+01:00">
          <i class="fa fa-clock-o"></i>
          Mon 25 June 2018
        </li>
        <li class="list-inline-item">
          <i class="fa fa-folder-open-o"></i>
          <a href="https://benhoyle.github.io/category/tweet2bible.html">Tweet2Bible</a>
        </li>
          <li class="list-inline-item">
            <i class="fa fa-user-o"></i>
              <a href="https://benhoyle.github.io/author/ben-hoyle.html">Ben Hoyle</a>          </li>
          <li class="list-inline-item">
            <i class="fa fa-files-o"></i>
              <a href="https://benhoyle.github.io/tag/initial_model.html">#initial_model</a>          </li>
      </ul>
    </footer>
  </article>
    </div>
  </div>

  <footer class="footer">
    <div class="container">
<div class="row">
  <p class="col-sm-6 text-sm-left">
    <a href="https://www.linkedin.com/in/benhoyle/" class="text-muted" target="_blank">Ben Hoyle</a> - <a href="https://twitter.com/bjh_ip" ><i class="fab fa-twitter"></i></a>
  </p>
  <p class="col-sm-6 text-sm-right text-muted">
    Generated by <a href="https://github.com/getpelican/pelican" class="text-muted" target="_blank">Pelican</a>
    / <a href="https://github.com/nairobilug/pelican-alchemy" class="text-muted" target="_blank">Adapted from &#x2728;</a>
  </p>
</div>    </div>
  </footer>
</body>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script>
$( document ).ready(function() {
    $('table').addClass('table table-bordered');
    $('tbody').addClass('table-striped');
    $('th').addClass('text-center');
});
</script></html>